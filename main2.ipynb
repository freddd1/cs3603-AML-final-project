{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "from utils.seed import set_seed\n",
    "set_seed(17)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\PycharmProjects\\cs3603-AML-final-project\\utils\\data_processing.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return_df['labels'][df['Overall'] >= cutoff] = 1\n",
      "C:\\Users\\itama\\PycharmProjects\\cs3603-AML-final-project\\utils\\data_processing.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return_df['labels'][df['Overall'] >= cutoff] = 1\n"
     ]
    }
   ],
   "source": [
    "from utils.data_processing import prepre_data_to_model\n",
    "from utils.data_processing import clean_text\n",
    "CUTOFF = 3\n",
    "COL_TEXT_TO_USE = 'title'\n",
    "\n",
    "train_base = prepre_data_to_model('data/semeval8/full_meta_en_train.csv', 'data/semeval8/en_train.csv', cutoff=CUTOFF, col_text_to_use=COL_TEXT_TO_USE)\n",
    "test = prepre_data_to_model('data/semeval8/evaluate_metadata.csv', 'data/semeval8/evaluate_dataset.csv', cutoff=CUTOFF, col_text_to_use=COL_TEXT_TO_USE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from cleantext import clean\n",
    "\n",
    "def clean_text(s):\n",
    "    # if not isinstance(s, str):\n",
    "    #     print(s)\n",
    "    # 1489983888\n",
    "    if s and isinstance(s, str):\n",
    "        s = s.lower()\n",
    "        s = clean(text=s)\n",
    "        s = \" \".join([word for word in s.split(' ') if word not in stopwords.words('english')])\n",
    "        return s\n",
    "    return ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "for col in ['text1', 'text2']:\n",
    "    # train_base.loc[:,col] = train_base[col].apply(clean_text)\n",
    "    test.loc[:, col] = test[col].apply(clean_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "((1052, 3), (263, 3), (220, 3))"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train_base, test_size=0.2, shuffle=True, random_state=11)\n",
    "train.shape, val.shape, test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# convert the data to SentencesDataset\n",
    "\n",
    "from datasets import SentencesDataset\n",
    "\n",
    "train_ds = SentencesDataset(train.text1.tolist(), train.text1.tolist(), train.labels.tolist())\n",
    "val_ds = SentencesDataset(val.text1.tolist(), val.text1.tolist(), val.labels.tolist())\n",
    "test_ds = SentencesDataset(test.text1.tolist(), test.text1.tolist(), test.labels.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from models import tBERT\n",
    "# from transformers import AdamW\n",
    "#\n",
    "# # PARAMETERS\n",
    "#\n",
    "# # train parameters\n",
    "# batch_size = 16\n",
    "# num_epochs = 1\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#\n",
    "# # lda parameters\n",
    "# n_topics = 70\n",
    "#\n",
    "# # embedding parameters\n",
    "# max_length = 256\n",
    "#\n",
    "# #optimizer parameters\n",
    "# lr = 5e-5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, shuffle=True, batch_size=16)\n",
    "val_dataloader = DataLoader(val_ds, shuffle=True, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# from utils.data_processing import create_sentences_corpus\n",
    "#\n",
    "# corpus = create_sentences_corpus(train_dataloader)\n",
    "# model = tBERT(corpus, n_topics=n_topics, max_length=max_length, device=device)\n",
    "#\n",
    "# optimizer = AdamW(model.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "# from trainer import Trainer\n",
    "# trainer = Trainer(model=model, optimizer=optimizer, train_dataloader=train_dataloader, num_epochs=num_epochs, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "# f1_train = trainer.evaluate(train_dataloader)\n",
    "# print(f'{f1_train=}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "from utils.data_processing import create_sentences_corpus\n",
    "import torch\n",
    "from models import tBERT\n",
    "from transformers import AdamW\n",
    "from trainer import Trainer\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "NUM_EPOCHS = 6\n",
    "N_TRAILS = 40\n",
    "\n",
    "def tbert_objective(trail):\n",
    "    # PARAMS SETTING\n",
    "    # Embedding\n",
    "    embeddings_length = trail.suggest_categorical('embeddings_length', [256, 512])\n",
    "    # General Model\n",
    "    lr = trail.suggest_loguniform('lr', 1e-6, 1e-3)\n",
    "    # LDA\n",
    "    n_topics = trail.suggest_int('n_topics', 50, 500)\n",
    "    alpha = trail.suggest_float('alpha', 1/50, 10)\n",
    "\n",
    "\n",
    "    corpus = create_sentences_corpus(train_dataloader)\n",
    "    model = tBERT(corpus, model_name='bert-base-uncased',num_labels=2,\n",
    "             max_length=embeddings_length, n_topics=n_topics, alpha=alpha, device=DEVICE)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    trainer = Trainer(model=model, optimizer=optimizer, train_dataloader=train_dataloader, num_epochs=NUM_EPOCHS, device=DEVICE)\n",
    "\n",
    "    trainer.train()\n",
    "    f1 = trainer.evaluate(val_dataloader)\n",
    "    return f1\n",
    "\n",
    "if not os.path.isfile('results/tBERT_best_params.json'):\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(tbert_objective, n_trials=N_TRAILS)\n",
    "\n",
    "    trail_ = study.best_trial\n",
    "    with open('results/tBERT_best_params.json', 'w') as f:\n",
    "        d = dict(trail_.params)\n",
    "        d['f1'] = trail_.values[0]\n",
    "        json.dump(d, f, indent=4)\n",
    "    print(f'BEST TRAIL:\\n f1:  {trail_.values}\\nparams: {trail_.params}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_ds, shuffle=True, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/330 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdebaa0a817f42578b29af9e3b3a1081"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get best parameters\n",
    "with open('results/tBERT_best_params.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# train tBERT\n",
    "corpus = create_sentences_corpus(train_dataloader)\n",
    "model = tBERT(corpus, model_name='bert-base-uncased', num_labels=2,\n",
    "             max_length=params['embeddings_length'], n_topics=params['n_topics'], alpha=params['alpha'], device=DEVICE)\n",
    "optimizer = AdamW(model.parameters(), lr=params['lr'])\n",
    "trainer = Trainer(model=model, optimizer=optimizer, train_dataloader=train_dataloader, num_epochs=NUM_EPOCHS, device=DEVICE)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "f1 =  trainer.evaluate(test_dataloader)\n",
    "f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "    # train tBERT\n",
    "corpus = create_sentences_corpus(train_dataloader)\n",
    "model = tBERT(corpus, model_name='bert-base-uncased', num_labels=2,\n",
    "             max_length=256, n_topics=100, alpha=5, device=DEVICE)\n",
    "optimizer = AdamW(model.parameters(), lr=0.00005)\n",
    "trainer = Trainer(model=model, optimizer=optimizer, train_dataloader=train_dataloader, num_epochs=1, device=DEVICE)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "labels, preds = trainer.evaluate(val_dataloader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels, preds = trainer.evaluate(val_dataloader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}